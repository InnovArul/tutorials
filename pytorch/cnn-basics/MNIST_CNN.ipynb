{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Handwritten digits classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![l](./pics/mnist.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to disable some warnings such as Implicit dimension choice for softmax, renamed variable etc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#-------- For obtaining the plots in the notebook -----#\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# torch module spefic to com puter vision\n",
    "from torchvision import datasets,transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------- Basic setup ------- #\n",
    "DATASET_DIRECTORY = './mnist/'\n",
    "SAVE_DIRECTORY    = './models/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------- Download training data, and set transformations to be applied -----#\n",
    "mnist_train = datasets.MNIST(DATASET_DIRECTORY,\n",
    "                             train=True,\n",
    "                             transform=transforms.ToTensor(),\n",
    "                             target_transform=None,\n",
    "                             download=True)\n",
    "\n",
    "mnist_test  = datasets.MNIST(DATASET_DIRECTORY,\n",
    "                             train=False,\n",
    "                             transform=transforms.ToTensor(),\n",
    "                             target_transform = None,\n",
    "                             download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset dimensions\n",
      "torch.Size([60000, 28, 28])\n",
      "Test dataset dimensions\n",
      "torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# ---- Dimensions of dataset ---- # \n",
    "# ---- Training dataset ---- #\n",
    "print(\"Training dataset dimensions\")\n",
    "print(mnist_train.train_data.size())\n",
    "\n",
    "# ---- Test dataset ---- #\n",
    "print(\"Test dataset dimensions\")\n",
    "print(mnist_test.test_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26d11424208>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Dislay some random image --- #\n",
    "imgindex = 100\n",
    "plt.imshow(mnist_test.test_data[imgindex].numpy(),cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple network\n",
    "\n",
    "![mnistnet](./pics/MNIST_CNN.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (mp1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (mp2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ---- Build the architecture --- #\n",
    "USE_CUDA = False\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Model,self).__init__()\n",
    "        \n",
    "        #--- The blocks are defined here ---#\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=6,kernel_size=5,stride=1,padding=0)\n",
    "        self.mp1   = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6,out_channels=16,kernel_size=5,stride=1,padding=0)\n",
    "        self.mp2   = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "        self.fc1   = nn.Linear(in_features=256,out_features=120)\n",
    "        self.fc2   = nn.Linear(in_features=120,out_features=84)\n",
    "        self.fc3  = nn.Linear(in_features=84,out_features=10)\n",
    "  \n",
    "        \n",
    "    #--- Forward propagation ---#\n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.mp1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.mp2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = x.view(-1,256)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "model = Model()\n",
    "\n",
    "if USE_CUDA:\n",
    "    model = model.cuda()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0205,  0.0151,  0.0707,  0.0547, -0.0489,  0.0072,  0.0950, -0.0137,\n",
      "          0.0694, -0.0398]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 28, 28)\n",
    "out = model(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function\n",
    "In this example, we will use Classification Cross-Entropy loss and SGD with momentum.<br>\n",
    "Cross Entropy loss is given as:- $L=-\\sum_i y_i \\log(p_i)$ and $p_i=\\frac{\\exp^{x_i}}{\\sum_k \\exp^{x_k}}$\n",
    "\n",
    "There are many other loss functions such as MSELoss, L1Loss etc. Visit [here](http://pytorch.org/docs/master/nn.html#loss-functions) for other loss functions.\n",
    "\n",
    "#### Stochastic Gradient Descent (SGD)\n",
    "$$w_{n+1} = w_{n} - \\eta \\triangle$$\n",
    "$$\\triangle = 0.9\\triangle + \\frac{\\partial L}{\\partial w}$$\n",
    "\n",
    "Although SGD is the most popular and basic optimizer that one should first try. There are many adaptive optimizers like Adagrad,Adadelta RMSProp and many more. Visit [here](http://pytorch.org/docs/master/optim.html) for other examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Settings for training ---- #\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini Batch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data :  469  batches of 128 samples each\n",
      "Test data :  79  batches of 128 samples each\n"
     ]
    }
   ],
   "source": [
    "# ----- Dataloades getting datasets ready for the network ---- #\n",
    "BATCH_SIZE    = 128\n",
    "train_loader = torch.utils.data.DataLoader(dataset=mnist_train,batch_size=BATCH_SIZE,shuffle=True)\n",
    "test_loader  = torch.utils.data.DataLoader(dataset=mnist_test,batch_size=BATCH_SIZE,shuffle=True)\n",
    "\n",
    "# ---- Knowing about how data is stored in the loader ---- #\n",
    "no_of_batches_train = len(train_loader)\n",
    "no_of_batches_test  = len(test_loader)\n",
    "print(\"Train data : \", no_of_batches_train, \" batches of 128 samples each\")\n",
    "print(\"Test data : \",no_of_batches_test, \" batches of 128 samples each\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                                                                  | 1/469 [00:00<01:03,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss (epoch 0: 2/469) : 2.3028913736343384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████████████████████████████████████████                                                                                            | 201/469 [00:28<00:39,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss (epoch 0: 202/469) : 1.3992910649221721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                       | 401/469 [00:56<00:09,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss (epoch 0: 402/469) : 0.8299770752774246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:06<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss (epoch 0.7367757746914049) : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                                                                  | 1/469 [00:00<01:00,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss (epoch 1: 2/469) : 0.1465969681739807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████████████████████████████████████████                                                                                            | 201/469 [00:28<00:39,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss (epoch 1: 202/469) : 0.14152476091933722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                       | 401/469 [00:57<00:10,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss (epoch 1: 402/469) : 0.12881082951540673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:07<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss (epoch 0.12584423288099292) : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                                                                  | 1/469 [00:00<01:03,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss (epoch 2: 2/469) : 0.057955287396907806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████████████████████████████████████████                                                                                            | 201/469 [00:29<00:38,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss (epoch 2: 202/469) : 0.08927565287466686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                       | 401/469 [00:57<00:09,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss (epoch 2: 402/469) : 0.08566860302782325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:07<00:00,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss (epoch 0.08394618515473312) : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                                                                  | 1/469 [00:00<00:58,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss (epoch 3: 2/469) : 0.07808117941021919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████████████████████████████████████████                                                                                            | 201/469 [00:29<00:40,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss (epoch 3: 202/469) : 0.0655300967063349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                       | 401/469 [00:57<00:09,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss (epoch 3: 402/469) : 0.06442345144106677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:07<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss (epoch 0.06418400251868564) : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                                                                  | 1/469 [00:00<01:01,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss (epoch 4: 2/469) : 0.036359163001179695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████████████████████████████████████████                                                                                            | 201/469 [00:29<00:38,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss (epoch 4: 202/469) : 0.05438606074946647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                       | 401/469 [00:57<00:09,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss (epoch 4: 402/469) : 0.05436334602386501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:07<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss (epoch 0.053985994710310944) : \n"
     ]
    }
   ],
   "source": [
    "# --- Training procedure ---- #\n",
    "\n",
    "from tqdm import tqdm\n",
    "EPOCH = 5\n",
    "running_loss = 0\n",
    "\n",
    "# --- Iterate over epoch ---- #\n",
    "for epoch in range(EPOCH):\n",
    "    \n",
    "    running_loss = 0\n",
    "    \n",
    "    # ---- Iterate over each batch --- # \n",
    "    for iter_, data in enumerate(tqdm(train_loader)):\n",
    "        inputs,labels = data\n",
    "        \n",
    "        # --- If CUDA is available move the tensor to GPU --- #\n",
    "        if USE_CUDA:\n",
    "            inputs,labels = inputs.cuda(),labels.cuda()            \n",
    "        \n",
    "        # --- To perform back propagation the tensors should be placed in Variable --- #\n",
    "        inputs,labels = Variable(inputs),Variable(labels)\n",
    "        \n",
    "        # --- Setting the obtained gradients to zero --- #\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # --- Forward propagation --- #\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # --- Backward propagation and optimization --- #\n",
    "        # --- Finding the error --- # \n",
    "        loss = criterion(outputs,labels)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        #--- Backward propogate ---#\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if(iter_ % 200 == 1):\n",
    "            print('average loss (epoch {}: {}/{}) : {}'.format(epoch, iter_+1, len(train_loader), running_loss / (iter_+1)))\n",
    "    \n",
    "    print('average loss (epoch {}) : '.format(running_loss / len(train_loader)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC1 ---> Weights :  torch.Size([6, 1, 5, 5])\n",
      "FC1 ---> Bias    :  torch.Size([6])\n",
      "FC2 ---> Weights :  torch.Size([16, 6, 5, 5])\n",
      "FC2 ---> Bias    :  torch.Size([16])\n",
      "FC3 ---> Weights :  torch.Size([120, 256])\n",
      "FC3 ---> Bias    :  torch.Size([120])\n"
     ]
    }
   ],
   "source": [
    "#--- Parameter dimensions ---#\n",
    "#--- This includes bias and weights ---#\n",
    "\n",
    "params = list(model.parameters())\n",
    "\n",
    "print(\"FC1 ---> Weights : \",params[0].size())\n",
    "print(\"FC1 ---> Bias    : \",params[1].size())\n",
    "\n",
    "print(\"FC2 ---> Weights : \",params[2].size())\n",
    "print(\"FC2 ---> Bias    : \",params[3].size())\n",
    "\n",
    "print(\"FC3 ---> Weights : \",params[4].size())\n",
    "print(\"FC3 ---> Bias    : \",params[5].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "Accuracy of the network on the 10000 test images: 98 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for data in test_loader:\n",
    "    images, labels = data\n",
    "    outputs = model(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    labels = labels\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "print(total)\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
